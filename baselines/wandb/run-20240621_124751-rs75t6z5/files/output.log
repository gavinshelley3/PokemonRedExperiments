-----------------------------
| time/              |      |
|    fps             | 142  |
|    iterations      | 1    |
|    time_elapsed    | 43   |
|    total_timesteps | 6144 |
-----------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 2          |
|    time_elapsed         | 164        |
|    total_timesteps      | 12288      |
| train/                  |            |
|    approx_kl            | 0.75106144 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.3        |
|    entropy_loss         | -0.427     |
|    explained_variance   | 0.356      |
|    learning_rate        | 0.0005     |
|    loss                 | -0.0736    |
|    n_updates            | 671        |
|    policy_gradient_loss | -0.0344    |
|    value_loss           | 0.00347    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 76         |
|    iterations           | 3          |
|    time_elapsed         | 241        |
|    total_timesteps      | 18432      |
| train/                  |            |
|    approx_kl            | 0.28659293 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.3        |
|    entropy_loss         | -0.663     |
|    explained_variance   | 0.481      |
|    learning_rate        | 0.0005     |
|    loss                 | -0.0864    |
|    n_updates            | 681        |
|    policy_gradient_loss | -0.0455    |
|    value_loss           | 0.00363    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 76         |
|    iterations           | 4          |
|    time_elapsed         | 320        |
|    total_timesteps      | 24576      |
| train/                  |            |
|    approx_kl            | 0.22511053 |
|    clip_fraction        | 0.262      |
|    clip_range           | 0.3        |
|    entropy_loss         | -0.575     |
|    explained_variance   | 0.121      |
|    learning_rate        | 0.0005     |
|    loss                 | -0.0943    |
|    n_updates            | 691        |
|    policy_gradient_loss | -0.0597    |
|    value_loss           | 0.00161    |
----------------------------------------
Traceback (most recent call last):
  File "C:\Users\Ian\IdeaProjects\PokemonRedExperiments\baselines\run_baseline_parallel_fast.py", line 135, in <module>
  File "C:\Users\Ian\IdeaProjects\PokemonRedExperiments\baselines\run_baseline_parallel_fast.py", line 130, in main
    model.save(sess_path / "final_model")  # Save the final model
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ian\AppData\Local\Programs\Python\Python311\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 308, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\Ian\AppData\Local\Programs\Python\Python311\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 259, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ian\AppData\Local\Programs\Python\Python311\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 178, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ian\AppData\Local\Programs\Python\Python311\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 197, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ian\AppData\Local\Programs\Python\Python311\Lib\site-packages\stable_baselines3\common\vec_env\vec_transpose.py", line 95, in step_wait
    observations, rewards, dones, infos = self.venv.step_wait()
                                          ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ian\AppData\Local\Programs\Python\Python311\Lib\site-packages\stable_baselines3\common\vec_env\subproc_vec_env.py", line 130, in step_wait
    results = [remote.recv() for remote in self.remotes]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ian\AppData\Local\Programs\Python\Python311\Lib\site-packages\stable_baselines3\common\vec_env\subproc_vec_env.py", line 130, in <listcomp>
    results = [remote.recv() for remote in self.remotes]
               ^^^^^^^^^^^^^
  File "C:\Users\Ian\AppData\Local\Programs\Python\Python311\Lib\multiprocessing\connection.py", line 250, in recv
    buf = self._recv_bytes()
          ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ian\AppData\Local\Programs\Python\Python311\Lib\multiprocessing\connection.py", line 321, in _recv_bytes
    waitres = _winapi.WaitForMultipleObjects(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt